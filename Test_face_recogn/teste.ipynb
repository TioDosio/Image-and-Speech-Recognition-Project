{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from deepface import DeepFace\n",
    "from PIL import Image, ImageDraw\n",
    "from IPython.display import display "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\andre\\\\Desktop\\\\Faculdade\\\\Image and Speech Recognition\\\\project\\\\Image-and-Speech-Recognition-Project\\\\Test_face_recogn\\\\test.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m display(image)\n\u001b[0;32m      4\u001b[0m DeepFace\u001b[38;5;241m.\u001b[39manalyze(img_path\u001b[38;5;241m=\u001b[39mimage_path)\n",
      "File \u001b[1;32mc:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\PIL\\Image.py:3469\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3466\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mrealpath(os\u001b[38;5;241m.\u001b[39mfspath(fp))\n\u001b[0;32m   3468\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[1;32m-> 3469\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3470\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   3471\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\andre\\\\Desktop\\\\Faculdade\\\\Image and Speech Recognition\\\\project\\\\Image-and-Speech-Recognition-Project\\\\Test_face_recogn\\\\test.jpg'"
     ]
    }
   ],
   "source": [
    "image_path = \"test.jpg\"\n",
    "image = Image.open(image_path)\n",
    "display(image)\n",
    "DeepFace.analyze(img_path=image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race: 100%|██████████| 4/4 [00:02<00:00,  1.50it/s]  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'emotion': {'angry': np.float32(1.3393676e-10),\n",
       "   'disgust': np.float32(3.504082e-17),\n",
       "   'fear': np.float32(4.6881677e-13),\n",
       "   'happy': np.float32(99.10732),\n",
       "   'sad': np.float32(6.747193e-08),\n",
       "   'surprise': np.float32(4.3783647e-08),\n",
       "   'neutral': np.float32(0.89268523)},\n",
       "  'dominant_emotion': 'happy',\n",
       "  'region': {'x': 531,\n",
       "   'y': 75,\n",
       "   'w': 121,\n",
       "   'h': 181,\n",
       "   'left_eye': (619, 150),\n",
       "   'right_eye': (561, 153)},\n",
       "  'face_confidence': np.float64(1.0),\n",
       "  'age': 27,\n",
       "  'gender': {'Woman': np.float32(0.0055428846), 'Man': np.float32(99.99445)},\n",
       "  'dominant_gender': 'Man',\n",
       "  'race': {'asian': np.float32(1.8689003),\n",
       "   'indian': np.float32(1.8488817),\n",
       "   'black': np.float32(83.49153),\n",
       "   'white': np.float32(4.2129507),\n",
       "   'middle eastern': np.float32(2.4788337),\n",
       "   'latino hispanic': np.float32(6.098903)},\n",
       "  'dominant_race': 'black'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DeepFace.analyze(img_path = \"test.jpg\", detector_backend='retinaface')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# draw image with bounding box\u001b[39;00m\n\u001b[0;32m      3\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mtest.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 4\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241m.\u001b[39mopen(image_path)\n\u001b[0;32m      5\u001b[0m analysis \u001b[38;5;241m=\u001b[39m DeepFace\u001b[38;5;241m.\u001b[39manalyze(img_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m, detector_backend\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mretinaface\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(analysis)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Image' is not defined"
     ]
    }
   ],
   "source": [
    "# draw image with bounding box\n",
    "\n",
    "image_path = \"images\\\\test.jpg\"\n",
    "image = Image.open(image_path)\n",
    "analysis = DeepFace.analyze(img_path = \"test.jpg\", detector_backend='retinaface')\n",
    "print(analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: SyntaxWarning: invalid escape sequence '\\M'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\M'\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_2164\\396064935.py:5: SyntaxWarning: invalid escape sequence '\\M'\n",
      "  modified_image_path = \"images\\MOD_test.jpg\"\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_2164\\396064935.py:5: SyntaxWarning: invalid escape sequence '\\M'\n",
      "  modified_image_path = \"images\\MOD_test.jpg\"\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'analysis' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m region \u001b[38;5;241m=\u001b[39m \u001b[43manalysis\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregion\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      2\u001b[0m draw \u001b[38;5;241m=\u001b[39m ImageDraw\u001b[38;5;241m.\u001b[39mDraw(image)\n\u001b[0;32m      3\u001b[0m draw\u001b[38;5;241m.\u001b[39mrectangle([(region[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m],region[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m]),(region[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m+\u001b[39mregion[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m], region[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m+\u001b[39mregion[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m])], outline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgreen\u001b[39m\u001b[38;5;124m'\u001b[39m, width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'analysis' is not defined"
     ]
    }
   ],
   "source": [
    "region = analysis[0]['region']\n",
    "draw = ImageDraw.Draw(image)\n",
    "draw.rectangle([(region['x'],region['y']),(region['x']+region['w'], region['y']+region['w'])], outline='green', width=5)\n",
    "\n",
    "modified_image_path = \"images\\MOD_test.jpg\"\n",
    "image.save(modified_image_path)\n",
    "\n",
    "image = Image.open(modified_image_path)\n",
    "display(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
