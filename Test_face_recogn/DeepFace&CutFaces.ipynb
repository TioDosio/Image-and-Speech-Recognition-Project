{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install deepface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from deepface import DeepFace\n",
    "from PIL import Image, ImageDraw\n",
    "from IPython.display import display\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "sys.path.append('aux_scripts.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the folder and image name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race: 100%|██████████| 4/4 [00:00<00:00,  6.51it/s]  \n"
     ]
    }
   ],
   "source": [
    "folder_name = \"../img/\"\n",
    "modified_folder_name = \"../dataset/images/processed/\"\n",
    "cropped_folder_name = \"../dataset/images/cropped/\"\n",
    "\n",
    "# Create the processed and cropped folders if they don't exist\n",
    "os.makedirs(modified_folder_name, exist_ok=True)\n",
    "os.makedirs(cropped_folder_name, exist_ok=True)\n",
    "\n",
    "for image_name in os.listdir(folder_name):\n",
    "    # Only process if the file is an image (e.g., PNG, JPG)\n",
    "    if image_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "        # Load image\n",
    "        image_path = os.path.join(folder_name, image_name)\n",
    "        image = Image.open(image_path)\n",
    "        image_draw = Image.open(image_path)\n",
    "\n",
    "        # Analyze the image\n",
    "        analysis = DeepFace.analyze(img_path=image_path, detector_backend='retinaface', enforce_detection=False)\n",
    "        \n",
    "        # Draw bounding boxes for each face detected\n",
    "        draw = ImageDraw.Draw(image_draw)\n",
    "        for idx, item in enumerate(analysis):\n",
    "            region = item['region']\n",
    "            x, y, w, h = region['x'], region['y'], region['w'], region['h']\n",
    "\n",
    "            offset_x = 0.2\n",
    "            offset_y = 0.15\n",
    "\n",
    "            # Crop the detected face\n",
    "            cropped_face = image.crop((x-((w*offset_x)/2), y-((h*offset_y)/2), x + w + w*offset_x, y + h + h*offset_y))\n",
    "            cropped_face_path = os.path.join(cropped_folder_name, f\"{image_name}_face_{idx + 1}.png\")\n",
    "            cropped_face.save(cropped_face_path)\n",
    "            #print(f\"Cropped face saved as {cropped_face_path}\")\n",
    "\n",
    "            # Draw rectangle on the original image\n",
    "            width_line = 2\n",
    "            draw.rectangle([(x-((w*offset_x)/2), y-((h*offset_y)/2)), (x + w + w*offset_x, y + h + h*offset_y)], outline='green', width=width_line)\n",
    "\n",
    "        # Save the image with bounding boxes\n",
    "        modified_image_path = os.path.join(modified_folder_name, \"MOD_\" + image_name)\n",
    "        image_draw.save(modified_image_path)\n",
    "        \n",
    "        # Optionally, display the processed image\n",
    "        #modified_image = Image.open(modified_image_path)\n",
    "        #display(modified_image)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
