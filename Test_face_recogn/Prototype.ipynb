{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install deepface\n",
    "#!pip install tf-keras\n",
    "#!pip install scikit-learn\n",
    "#!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepface import DeepFace\n",
    "from PIL import Image, ImageDraw\n",
    "from IPython.display import display\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the folder and image name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = \"../dataset/images/original/\"\n",
    "modified_folder_name = \"../dataset/images/processed/\"\n",
    "cropped_folder_name = \"../dataset/images/cropped/\"\n",
    "\n",
    "# Create the processed and cropped folders if they don't exist\n",
    "os.makedirs(modified_folder_name, exist_ok=True)\n",
    "os.makedirs(cropped_folder_name, exist_ok=True)\n",
    "\n",
    "for image_name in os.listdir(folder_name):\n",
    "    # Only process if the file is an image (e.g., PNG, JPG)\n",
    "    if image_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "        # Load image\n",
    "        image_path = os.path.join(folder_name, image_name)\n",
    "        image = Image.open(image_path)\n",
    "\n",
    "        # Analyze the image\n",
    "        analysis = DeepFace.analyze(img_path=image_path, detector_backend='retinaface', enforce_detection=False)\n",
    "        \n",
    "        # Draw bounding boxes for each face detected\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        for idx, item in enumerate(analysis):\n",
    "            region = item['region']\n",
    "            x, y, w, h = region['x'], region['y'], region['w'], region['h']\n",
    "\n",
    "            # Draw rectangle on the original image\n",
    "            draw.rectangle([(x, y), (x + w, y + h)], outline='green', width=4)\n",
    "\n",
    "            # Crop the detected face\n",
    "            cropped_face = image.crop((x, y, x + w, y + h))\n",
    "            cropped_face_path = os.path.join(cropped_folder_name, f\"{image_name}_face_{idx + 1}.png\")\n",
    "            cropped_face.save(cropped_face_path)\n",
    "            print(f\"Cropped face saved as {cropped_face_path}\")\n",
    "\n",
    "        # Save the image with bounding boxes\n",
    "        modified_image_path = os.path.join(modified_folder_name, \"MOD_\" + image_name)\n",
    "        image.save(modified_image_path)\n",
    "        \n",
    "        # Optionally, display the processed image\n",
    "        modified_image = Image.open(modified_image_path)\n",
    "        display(modified_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN creation and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to the original dataset\n",
    "dataset_dir = '../dataset'  # Original dataset directory\n",
    "mask_dir = os.path.join(dataset_dir, 'mask')\n",
    "no_mask_dir = os.path.join(dataset_dir, 'no_mask')\n",
    "\n",
    "# Paths for training and validation directories\n",
    "train_dir = 'dataset/train'\n",
    "val_dir = 'dataset/val'\n",
    "\n",
    "# Create directories for train/val split\n",
    "os.makedirs(os.path.join(train_dir, 'mask'), exist_ok=True)\n",
    "os.makedirs(os.path.join(train_dir, 'no_mask'), exist_ok=True)\n",
    "os.makedirs(os.path.join(val_dir, 'mask'), exist_ok=True)\n",
    "os.makedirs(os.path.join(val_dir, 'no_mask'), exist_ok=True)\n",
    "\n",
    "# Function to split and create symlinks\n",
    "def split_and_link_files(source_dir, train_class_dir, val_class_dir, test_size=0.2):\n",
    "    # Get all files in the source directory\n",
    "    files = os.listdir(source_dir)\n",
    "    \n",
    "    # Split into training and validation sets\n",
    "    train_files, val_files = train_test_split(files, test_size=test_size, random_state=42)\n",
    "    \n",
    "    # Create symlinks for training files\n",
    "    for file in train_files:\n",
    "        source_file = os.path.join(source_dir, file)\n",
    "        target_file = os.path.join(train_class_dir, file)\n",
    "        os.symlink(source_file, target_file)  # Create a symbolic link\n",
    "    \n",
    "    # Create symlinks for validation files\n",
    "    for file in val_files:\n",
    "        source_file = os.path.join(source_dir, file)\n",
    "        target_file = os.path.join(val_class_dir, file)\n",
    "        os.symlink(source_file, target_file)  # Create a symbolic link\n",
    "    \n",
    "    # Return the counts of training and validation files\n",
    "    return len(train_files), len(val_files)\n",
    "\n",
    "# Split and link the \"mask\" images\n",
    "mask_train_count, mask_val_count = split_and_link_files(mask_dir, os.path.join(train_dir, 'mask'), os.path.join(val_dir, 'mask'))\n",
    "\n",
    "# Split and link the \"no_mask\" images\n",
    "no_mask_train_count, no_mask_val_count = split_and_link_files(no_mask_dir, os.path.join(train_dir, 'no_mask'), os.path.join(val_dir, 'no_mask'))\n",
    "\n",
    "# Print the quantities for each class\n",
    "print(\"Dataset Quantities:\")\n",
    "print(f\"Mask - Train: {mask_train_count}, Validation: {mask_val_count}\")\n",
    "print(f\"No Mask - Train: {no_mask_train_count}, Validation: {no_mask_val_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Paths to the training and validation datasets\n",
    "train_dir = 'dataset/train'\n",
    "val_dir = 'dataset/val'\n",
    "\n",
    "# Image size (resize all images to the same size)\n",
    "image_size = (128, 128)\n",
    "\n",
    "# Rescale the pixel values for training set (without augmentation)\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Rescale the pixel values for validation set (no augmentation)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load the training dataset from the directory\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,  # Directory for the training images\n",
    "    target_size=image_size,  # Resize the images\n",
    "    batch_size=32,\n",
    "    class_mode='binary',  # Binary classification (mask/no mask)\n",
    "    shuffle=True  # Shuffle training images\n",
    ")\n",
    "\n",
    "# Load the validation dataset from the directory\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    val_dir,  # Directory for the validation images\n",
    "    target_size=image_size,  # Resize the images\n",
    "    batch_size=32,\n",
    "    class_mode='binary',  # Binary classification (mask/no mask)\n",
    "    shuffle=False  # Do not shuffle validation images\n",
    ")\n",
    "\n",
    "# Build the CNN model\n",
    "model = models.Sequential([\n",
    "    # Convolutional Layer 1\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # Convolutional Layer 2\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # Convolutional Layer 3\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # Flatten the output to feed into fully connected layers\n",
    "    layers.Flatten(),\n",
    "    \n",
    "    # Dense Layer 1\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    \n",
    "    # Output Layer: Sigmoid activation for binary classification\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model with binary crossentropy loss (for binary classification) and Adam optimizer\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=10,  # Number of epochs to train the model\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size\n",
    ")\n",
    "\n",
    "i=1\n",
    "# Save the trained model\n",
    "model.save('face_mask_classifier_no_augmentatio_'+i+'.h5')\n",
    "i+=1\n",
    "# Plot accuracy and loss curves\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='train accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='validation accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='train loss')\n",
    "plt.plot(history.history['val_loss'], label='validation loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
